# ğŸŒ CT-MON Challenge SI

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um pipeline completo de prediÃ§Ã£o multivariada para mÃ©tricas de qualidade de transmissÃ£o em redes acadÃªmicas. Desenvolvido com base nos dados do Desafio de Dados CT-MON da RNP (Rede Nacional de Ensino e Pesquisa), o sistema Ã© capaz de prever com 10 minutos de antecedÃªncia a qualidade do trÃ¡fego DASH entre clientes e servidores distribuÃ­dos regionalmente.

ğŸ“‚ Dataset disponÃ­vel em:
https://www.kaggle.com/competitions/open-data-challenge-ct-mon-rnp/data

### ğŸ¯ Objetivo Principal

Desenvolver um modelo de machine learning para predizer:
- **Taxa de transmissÃ£o mÃ©dia** futura (5 e 10 minutos Ã  frente)
- **Desvio padrÃ£o** da taxa de transmissÃ£o (5 e 10 minutos Ã  frente)

Essas prediÃ§Ãµes permitem antecipar problemas de qualidade de rede e otimizar a experiÃªncia do usuÃ¡rio em transmissÃµes de vÃ­deo DASH.

## ğŸ” Problema de NegÃ³cio

Em redes acadÃªmicas, a **qualidade da transmissÃ£o de dados** Ã© crucial para:
- Aulas online e videoconferÃªncias
- Pesquisas colaborativas
- Acesso a recursos educacionais digitais

A capacidade de **prever degradaÃ§Ãµes na qualidade** permite:
- âœ… AÃ§Ãµes preventivas de manutenÃ§Ã£o
- âœ… Roteamento inteligente de trÃ¡fego
- âœ… Melhor experiÃªncia do usuÃ¡rio final
- âœ… OtimizaÃ§Ã£o de recursos de rede

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

### Abordagem TÃ©cnica

- **Modelo**: Random Forest com mÃºltiplas saÃ­das (MultiOutputRegressor)
- **Features**: ExtraÃ§Ã£o de caracterÃ­sticas estatÃ­sticas de sÃ©ries temporais
- **ValidaÃ§Ã£o**: ValidaÃ§Ã£o cruzada temporal (TimeSeriesSplit)
- **OtimizaÃ§Ã£o**: Busca aleatÃ³ria de hiperparÃ¢metros (RandomizedSearchCV)
- **Baseline**: ComparaÃ§Ã£o com modelo estatÃ­stico (mÃ©dia histÃ³rica)

### VariÃ¡veis Alvo

| VariÃ¡vel | DescriÃ§Ã£o |
|----------|-----------|
| `mean_1` | Taxa mÃ©dia no minuto T+5 |
| `std_1` | Desvio padrÃ£o no minuto T+5 |
| `mean_2` | Taxa mÃ©dia no minuto T+10 |
| `std_2` | Desvio padrÃ£o no minuto T+10 |

## ğŸ“‚ Estrutura do Projeto

```
ct-mon-challenge-SI/
â”œâ”€â”€ ğŸ“„ main.py                         # Script principal - orquestra todo o pipeline
â”œâ”€â”€ ğŸ“„ requirements.txt                # DependÃªncias do projeto
â”œâ”€â”€ ğŸ“„ README.md                       # Este arquivo
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“„ data_loader.py              # Download e carregamento dos dados
â”‚   â”œâ”€â”€ ğŸ“„ preprocessor.py             # PrÃ©-processamento e feature engineering
â”‚   â”œâ”€â”€ ğŸ“„ model.py                    # Modelo Random Forest e otimizaÃ§Ã£o
â”‚   â”œâ”€â”€ ğŸ“„ evaluator.py                # AvaliaÃ§Ã£o e mÃ©tricas de performance
â”‚   â”œâ”€â”€ ğŸ“„ utils.py                    # UtilitÃ¡rios e visualizaÃ§Ãµes
â”‚   â””â”€â”€ ğŸ“ __pycache__/                # Cache Python (ignorado no Git)
â”œâ”€â”€ ğŸ“ data/                           # Dados baixados e processados (gerada automaticamente)
â”‚   â”œâ”€â”€ ğŸ“„ open-data.zip               # Arquivo compactado baixado do Google Drive
â”‚   â”œâ”€â”€ ğŸ“ Train/                      # Dados de treinamento organizados
â”‚   â”‚   â””â”€â”€ ğŸ“ dash/                   # Dados DASH por cliente/servidor
â”‚   â”‚       â”œâ”€â”€ ğŸ“ ba/                 # Clientes da Bahia
â”‚   â”‚       â”œâ”€â”€ ğŸ“ rj/                 # Clientes do Rio de Janeiro
â”‚   â”‚       â””â”€â”€ ğŸ“ ...                 # Outras regiÃµes
â”‚   â””â”€â”€ ğŸ“ Test/                       # Arquivos de teste para prediÃ§Ã£o
â”‚       â””â”€â”€ ğŸ“„ *.json                  # RequisiÃ§Ãµes de prediÃ§Ã£o (submissÃ£o)
â””â”€â”€ ğŸ“ results/                        # Resultados e artefatos (gerada automaticamente)
    â”œâ”€â”€ ğŸ“„ submission.csv              # PrediÃ§Ãµes finais para submissÃ£o
    â”œâ”€â”€ ğŸ“„ metrics_report.csv          # RelatÃ³rio comparativo de mÃ©tricas
    â”œâ”€â”€ ğŸ“„ best_hyperparameters.csv    # Melhores hiperparÃ¢metros encontrados
    â”œâ”€â”€ ğŸ“„ features_documentation.csv  # DocumentaÃ§Ã£o das features criadas
    â””â”€â”€ ğŸ“ figures/                    # VisualizaÃ§Ãµes geradas
        â”œâ”€â”€ ğŸ“Š mse_comparison.png      # ComparaÃ§Ã£o MSE
        â”œâ”€â”€ ğŸ“Š mae_comparison.png      # ComparaÃ§Ã£o MAE
        â””â”€â”€ ğŸ“Š mape_comparison.png     # ComparaÃ§Ã£o MAPE
```

## ğŸ”„ Pipeline de ExecuÃ§Ã£o

### 1. ğŸ“¥ Coleta de Dados (`data_loader.py`)

## ğŸ“ Detalhamento das Pastas

### ğŸ“¥ Pasta `data/` - Armazenamento dos Dados

Esta pasta Ã© **criada automaticamente** pelo `data_loader.py` e contÃ©m todos os dados do **Desafio CT-MON da RNP**.

#### Estrutura dos Dados:
```
data/
â”œâ”€â”€ open-data.zip            # Arquivo compactado original (Google Drive)
â”œâ”€â”€ Train/                   # Dados de treinamento
â”‚   â””â”€â”€ dash/                # Dados DASH organizados por regiÃ£o
â”‚       â”œâ”€â”€ ba/              # Clientes da Bahia
â”‚       â”œâ”€â”€ rj/              # Clientes do Rio de Janeiro
â”‚       â”œâ”€â”€ sp/              # Clientes de SÃ£o Paulo
â”‚       â””â”€â”€ ...              # Outras regiÃµes brasileiras
â””â”€â”€ Test/                    # Dados de teste para submissÃ£o
    â””â”€â”€ *.json               # Arquivos JSON com sÃ©ries temporais
```

#### ConteÃºdo Detalhado:
- **`Train/dash/*/`**: Dados de treinamento organizados por pares cliente-servidor
  - Cada pasta regional contÃ©m arquivos `.json` com mÃ©tricas de trÃ¡fego DASH
  - Dados incluem timestamps, taxas de transmissÃ£o e variabilidade
- **`Test/`**: Arquivos de teste com as Ãºltimas 10 observaÃ§Ãµes
  - Utilizados para gerar prediÃ§Ãµes dos prÃ³ximos 2 instantes (T+5 e T+10 minutos)
- **`open-data.zip`**: Arquivo original baixado automaticamente via Google Drive

### ğŸ“Š Pasta `results/` - Artefatos e Resultados

Esta pasta Ã© **gerada automaticamente** durante a execuÃ§Ã£o e contÃ©m todos os **artefatos produzidos pelo pipeline**.

#### Estrutura dos Resultados:
```
results/
â”œâ”€â”€ submission.csv                  # Arquivo final de submissÃ£o
â”œâ”€â”€ metrics_report.csv              # RelatÃ³rio de performance
â”œâ”€â”€ best_hyperparameters.csv        # HiperparÃ¢metros otimizados
â”œâ”€â”€ features_documentation.csv      # DocumentaÃ§Ã£o das features
â””â”€â”€ figures/                        # VisualizaÃ§Ãµes comparativas
    â”œâ”€â”€ mse_comparison.png          # GrÃ¡fico de comparaÃ§Ã£o MSE
    â”œâ”€â”€ mae_comparison.png          # GrÃ¡fico de comparaÃ§Ã£o MAE
    â””â”€â”€ mape_comparison.png         # GrÃ¡fico de comparaÃ§Ã£o MAPE
```

#### DescriÃ§Ã£o dos Arquivos:

| Arquivo | DescriÃ§Ã£o | Formato |
|---------|-----------|---------|
| `submission.csv` | PrediÃ§Ãµes finais (`id`, `mean_1`, `std_1`, `mean_2`, `std_2`) | Pronto para submissÃ£o |
| `metrics_report.csv` | MÃ©tricas comparativas (MSE, RMSE, MAE, MAPE, RÂ²) | AnÃ¡lise de performance |
| `best_hyperparameters.csv` | Melhores configuraÃ§Ãµes do RandomizedSearchCV | Para reprodutibilidade |
| `features_documentation.csv` | Justificativas tÃ©cnicas de cada feature criada | DocumentaÃ§Ã£o cientÃ­fica |
| `figures/*.png` | GrÃ¡ficos de barras comparando modelos vs baseline | VisualizaÃ§Ã£o executiva |
- Download automÃ¡tico dos dados via Google Drive
- ExtraÃ§Ã£o do arquivo ZIP na pasta `data/`
- VerificaÃ§Ã£o de integridade dos arquivos
- CriaÃ§Ã£o automÃ¡tica da estrutura de pastas se nÃ£o existir

### 2. ğŸ› ï¸ PrÃ©-processamento (`preprocessor.py`)

#### AgregaÃ§Ã£o Temporal
- **Janelas de 5 minutos**: Reagrupamento dos dados originais
- **SequÃªncias de 1 hora**: 12 janelas consecutivas para extraÃ§Ã£o de features

#### Feature Engineering
Para cada sequÃªncia, sÃ£o extraÃ­das as seguintes caracterÃ­sticas:

| Feature | DescriÃ§Ã£o | Justificativa |
|---------|-----------|---------------|
| `rate_mean` | MÃ©dia das taxas nos Ãºltimos 10 intervalos | TendÃªncia central dos dados |
| `rate_std` | Desvio padrÃ£o nos Ãºltimos 10 intervalos | Variabilidade da rede |
| `last_rate` | Ãšltima taxa observada | Estado mais recente |
| `last_std` | Ãšltimo desvio padrÃ£o observado | Variabilidade recente |
| `coef_var` | Coeficiente de variaÃ§Ã£o (std/mean) | Estabilidade relativa |
| `delta` | DiferenÃ§a entre penÃºltimo e Ãºltimo valor | TendÃªncia de mudanÃ§a |
| `slope` | InclinaÃ§Ã£o da regressÃ£o linear | DireÃ§Ã£o da tendÃªncia |

### 3. ğŸ¤– Modelagem (`model.py`)

#### Algoritmo Escolhido
**Random Forest** foi selecionado por:
- âœ… Robustez a outliers
- âœ… Capacidade de capturar relaÃ§Ãµes nÃ£o-lineares
- âœ… Interpretabilidade atravÃ©s da importÃ¢ncia das features
- âœ… Performance consistente em dados tabulares

#### OtimizaÃ§Ã£o de HiperparÃ¢metros
```python
param_distributions = {
    'estimator__n_estimators': [50, 100, 200, 300],
    'estimator__max_depth': [10, 20, 30, None],
    'estimator__min_samples_split': [2, 5, 10],
    'estimator__min_samples_leaf': [1, 2, 4],
    'estimator__max_features': ['sqrt', 'log2', None]
}
```

### 4. ğŸ“Š AvaliaÃ§Ã£o (`evaluator.py`)

#### MÃ©tricas de Performance
- **MSE** (Mean Squared Error): Penaliza erros grandes
- **RMSE** (Root Mean Squared Error): InterpretÃ¡vel na unidade original
- **MAE** (Mean Absolute Error): Robusta a outliers
- **MAPE** (Mean Absolute Percentage Error): Erro relativo
- **RÂ²** (Coeficiente de DeterminaÃ§Ã£o): ProporÃ§Ã£o da variÃ¢ncia explicada

#### ValidaÃ§Ã£o Temporal
- **TimeSeriesSplit**: Respeita a ordem cronolÃ³gica dos dados
- **5 folds**: AvaliaÃ§Ã£o robusta da performance

### 5. ğŸ“ˆ Resultados e VisualizaÃ§Ãµes (`utils.py`)

#### Arquivos Gerados na Pasta `results/`
- `submission.csv`: PrediÃ§Ãµes finais no formato solicitado
- `metrics_report.csv`: ComparaÃ§Ã£o detalhada das mÃ©tricas
- `best_hyperparameters.csv`: Melhores configuraÃ§Ãµes encontradas
- `features_documentation.csv`: DocumentaÃ§Ã£o das features criadas
- `performance_comparison.png`: GrÃ¡fico comparativo dos modelos

> **Nota**: A pasta `results/` Ã© criada automaticamente durante a execuÃ§Ã£o

## ğŸš€ Como Executar

### 1. PrÃ©-requisitos
```bash
# Python 3.12 ou superior
python --version

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. ExecuÃ§Ã£o
```bash
# Executar pipeline completo
python main.py
```

O script irÃ¡:
1. Baixar os dados automaticamente para `data/`
2. Executar todo o pipeline de ML
3. Gerar todos os arquivos de resultado em `results/`
4. Exibir mÃ©tricas no console

> **ğŸ“ Pastas Criadas Automaticamente:**
> - `data/`: ContÃ©m os dados originais baixados e extraÃ­dos
> - `results/`: ContÃ©m todos os artefatos gerados pelo pipeline

### 3. Estrutura dos Arquivos ApÃ³s ExecuÃ§Ã£o
```
ct-mon-challenge-SI/
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ ğŸ“„ open-data.zip               # Dataset original compactado
â”‚   â”œâ”€â”€ ğŸ“ Train/dash/                 # Dados de treinamento por regiÃ£o
â”‚   â””â”€â”€ ğŸ“ Test/                       # Dados de teste (*.json)
â””â”€â”€ ğŸ“ results/
    â”œâ”€â”€ ğŸ“„ submission.csv              # PrediÃ§Ãµes finais
    â”œâ”€â”€ ğŸ“„ metrics_report.csv          # RelatÃ³rio de mÃ©tricas
    â”œâ”€â”€ ğŸ“„ best_hyperparameters.csv    # Melhores hiperparÃ¢metros
    â”œâ”€â”€ ğŸ“„ features_documentation.csv  # DocumentaÃ§Ã£o das features
    â””â”€â”€ ğŸ“ figures/                    # VisualizaÃ§Ãµes (PNG)
        â”œâ”€â”€ ğŸ“Š mse_comparison.png
        â”œâ”€â”€ ğŸ“Š mae_comparison.png
        â””â”€â”€ ğŸ“Š mape_comparison.png
```

## ğŸ“Š Resultados Obtidos

### Performance do Modelo

| Dataset | Modelo | MSE | RMSE | MAE | MAPE | RÂ² |
|---------|--------|-----|------|-----|------|-----|
| **Treinamento** | Random Forest | 460M | 21.4K | 11.4K | 0.167 | **0.671** |
| Treinamento | Baseline | 1.38Bi | 37.2K | 22.4K | 0.250 | 0.000 |
| **Teste** | Random Forest | 477M | 21.8K | 11.5K | 0.064 | **0.654** |
| Teste | Baseline | 1.64Bi | 40.5K | 27.3K | 0.133 | -0.020 |

### ğŸ¯ Principais Conquistas

âœ… **67% de variÃ¢ncia explicada** no conjunto de treinamento  
âœ… **65% de variÃ¢ncia explicada** no conjunto de teste  
âœ… **ReduÃ§Ã£o de 66% no MSE** comparado ao baseline  
âœ… **ReduÃ§Ã£o de 48% no MAE** comparado ao baseline  
âœ… **GeneralizaÃ§Ã£o consistente** entre treino e teste  

## ğŸ› ï¸ Tecnologias Utilizadas

### Core
- **Python 3.12+**: Linguagem principal
- **Scikit-learn**: Framework de machine learning
- **Pandas**: ManipulaÃ§Ã£o de dados
- **NumPy**: ComputaÃ§Ã£o numÃ©rica

### EspecÃ­ficas
- **RandomForestRegressor**: Algoritmo de prediÃ§Ã£o
- **MultiOutputRegressor**: MÃºltiplas saÃ­das simultÃ¢neas
- **TimeSeriesSplit**: ValidaÃ§Ã£o temporal
- **RandomizedSearchCV**: OtimizaÃ§Ã£o de hiperparÃ¢metros

### UtilitÃ¡rios
- **Matplotlib/Seaborn**: VisualizaÃ§Ãµes
- **gdown**: Download automÃ¡tico de datasets
- **CSV/JSON**: PersistÃªncia de dados

## ğŸ”® Potenciais ExtensÃµes

### Curto Prazo
- [ ] **XGBoost/LightGBM**: Algoritmos de boosting
- [ ] **Feature Selection**: SeleÃ§Ã£o automÃ¡tica de caracterÃ­sticas
- [ ] **Cross-validation estratificada**: Por cliente/servidor

### MÃ©dio Prazo
- [ ] **LSTM/GRU**: Redes neurais recorrentes
- [ ] **Prophet**: Modelagem de sazonalidade
- [ ] **Ensemble Methods**: CombinaÃ§Ã£o de modelos

### Longo Prazo
- [ ] **Graph Neural Networks**: Explorar topologia da rede
- [ ] **Real-time Prediction**: Pipeline em tempo real
- [ ] **MLOps**: Deploy com MLflow/Kubeflow

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.
