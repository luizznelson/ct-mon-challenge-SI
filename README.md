# üåê CT-MON Challenge SI

## üìã Descri√ß√£o do Projeto

Este projeto implementa um pipeline completo de predi√ß√£o multivariada para m√©tricas de qualidade de transmiss√£o em redes acad√™micas. Desenvolvido com base nos dados do Desafio de Dados CT-MON da RNP (Rede Nacional de Ensino e Pesquisa), o sistema √© capaz de prever com 10 minutos de anteced√™ncia a qualidade do tr√°fego DASH entre clientes e servidores distribu√≠dos regionalmente.

üìÇ Dataset dispon√≠vel em:
https://www.kaggle.com/competitions/open-data-challenge-ct-mon-rnp/data

### üéØ Objetivo Principal

Desenvolver um modelo de machine learning para predizer:
- **Taxa de transmiss√£o m√©dia** futura (5 e 10 minutos √† frente)
- **Desvio padr√£o** da taxa de transmiss√£o (5 e 10 minutos √† frente)

Essas predi√ß√µes permitem antecipar problemas de qualidade de rede e otimizar a experi√™ncia do usu√°rio em transmiss√µes de v√≠deo DASH.

## üîç Problema de Neg√≥cio

Em redes acad√™micas, a **qualidade da transmiss√£o de dados** √© crucial para:
- Aulas online e videoconfer√™ncias
- Pesquisas colaborativas
- Acesso a recursos educacionais digitais

A capacidade de **prever degrada√ß√µes na qualidade** permite:
- ‚úÖ A√ß√µes preventivas de manuten√ß√£o
- ‚úÖ Roteamento inteligente de tr√°fego
- ‚úÖ Melhor experi√™ncia do usu√°rio final
- ‚úÖ Otimiza√ß√£o de recursos de rede

## üèóÔ∏è Arquitetura da Solu√ß√£o

### Abordagem T√©cnica

- **Modelo**: Random Forest com m√∫ltiplas sa√≠das (MultiOutputRegressor)
- **Features**: Extra√ß√£o de caracter√≠sticas estat√≠sticas de s√©ries temporais
- **Valida√ß√£o**: Valida√ß√£o cruzada temporal (TimeSeriesSplit)
- **Otimiza√ß√£o**: Busca aleat√≥ria de hiperpar√¢metros (RandomizedSearchCV)
- **Baseline**: Compara√ß√£o com modelo estat√≠stico (m√©dia hist√≥rica)

### Vari√°veis Alvo

| Vari√°vel | Descri√ß√£o |
|----------|-----------|
| `mean_1` | Taxa m√©dia no minuto T+5 |
| `std_1` | Desvio padr√£o no minuto T+5 |
| `mean_2` | Taxa m√©dia no minuto T+10 |
| `std_2` | Desvio padr√£o no minuto T+10 |

## üìÇ Estrutura do Projeto

```
ct-mon-challenge-SI/
‚îú‚îÄ‚îÄ üìÑ main.py                         # Script principal - orquestra todo o pipeline
‚îú‚îÄ‚îÄ üìÑ requirements.txt                # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ üìÑ README.md                       # Este arquivo
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ data_loader.py              # Download e carregamento dos dados
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ preprocessor.py             # Pr√©-processamento e feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ model.py                    # Modelo Random Forest e otimiza√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ evaluator.py                # Avalia√ß√£o e m√©tricas de performance
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ utils.py                    # Utilit√°rios e visualiza√ß√µes
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ __pycache__/                # Cache Python (ignorado no Git)
‚îú‚îÄ‚îÄ üìÅ data/                           # Dados baixados e processados (gerada automaticamente)
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ open-data.zip               # Arquivo compactado baixado do Google Drive
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ Train/                      # Dados de treinamento organizados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ dash/                   # Dados DASH por cliente/servidor
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÅ ba/                 # Clientes da Bahia
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ üìÅ rj/                 # Clientes do Rio de Janeiro
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ üìÅ ...                 # Outras regi√µes
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ Test/                       # Arquivos de teste para predi√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ üìÑ *.json                  # Requisi√ß√µes de predi√ß√£o (submiss√£o)
‚îî‚îÄ‚îÄ üìÅ results/                        # Resultados e artefatos (gerada automaticamente)
    ‚îú‚îÄ‚îÄ üìÑ submission.csv              # Predi√ß√µes finais para submiss√£o
    ‚îú‚îÄ‚îÄ üìÑ metrics_report.csv          # Relat√≥rio comparativo de m√©tricas
    ‚îú‚îÄ‚îÄ üìÑ best_hyperparameters.csv    # Melhores hiperpar√¢metros encontrados
    ‚îú‚îÄ‚îÄ üìÑ features_documentation.csv  # Documenta√ß√£o das features criadas
    ‚îî‚îÄ‚îÄ üìÅ figures/                    # Visualiza√ß√µes geradas
        ‚îú‚îÄ‚îÄ üìä mse_comparison.png      # Compara√ß√£o MSE
        ‚îú‚îÄ‚îÄ üìä mae_comparison.png      # Compara√ß√£o MAE
        ‚îî‚îÄ‚îÄ üìä mape_comparison.png     # Compara√ß√£o MAPE
```

## üîÑ Pipeline de Execu√ß√£o

### 1. üì• Coleta de Dados (`data_loader.py`)

## üìÅ Detalhamento das Pastas

### üì• Pasta `data/` - Armazenamento dos Dados

Esta pasta √© **criada automaticamente** pelo `data_loader.py` e cont√©m todos os dados do **Desafio CT-MON da RNP**.

#### Estrutura dos Dados:
```
data/
‚îú‚îÄ‚îÄ open-data.zip            # Arquivo compactado original (Google Drive)
‚îú‚îÄ‚îÄ Train/                   # Dados de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ dash/                # Dados DASH organizados por regi√£o
‚îÇ       ‚îú‚îÄ‚îÄ ba/              # Clientes da Bahia
‚îÇ       ‚îú‚îÄ‚îÄ rj/              # Clientes do Rio de Janeiro
‚îÇ       ‚îú‚îÄ‚îÄ sp/              # Clientes de S√£o Paulo
‚îÇ       ‚îî‚îÄ‚îÄ ...              # Outras regi√µes brasileiras
‚îî‚îÄ‚îÄ Test/                    # Dados de teste para submiss√£o
    ‚îî‚îÄ‚îÄ *.json               # Arquivos JSON com s√©ries temporais
```

#### Conte√∫do Detalhado:
- **`Train/dash/*/`**: Dados de treinamento organizados por pares cliente-servidor
  - Cada pasta regional cont√©m arquivos `.json` com m√©tricas de tr√°fego DASH
  - Dados incluem timestamps, taxas de transmiss√£o e variabilidade
- **`Test/`**: Arquivos de teste com as √∫ltimas 10 observa√ß√µes
  - Utilizados para gerar predi√ß√µes dos pr√≥ximos 2 instantes (T+5 e T+10 minutos)
- **`open-data.zip`**: Arquivo original baixado automaticamente via Google Drive

### üìä Pasta `results/` - Artefatos e Resultados

Esta pasta √© **gerada automaticamente** durante a execu√ß√£o e cont√©m todos os **artefatos produzidos pelo pipeline**.

#### Estrutura dos Resultados:
```
results/
‚îú‚îÄ‚îÄ submission.csv                  # Arquivo final de submiss√£o
‚îú‚îÄ‚îÄ metrics_report.csv              # Relat√≥rio de performance
‚îú‚îÄ‚îÄ best_hyperparameters.csv        # Hiperpar√¢metros otimizados
‚îú‚îÄ‚îÄ features_documentation.csv      # Documenta√ß√£o das features
‚îî‚îÄ‚îÄ figures/                        # Visualiza√ß√µes comparativas
    ‚îú‚îÄ‚îÄ mse_comparison.png          # Gr√°fico de compara√ß√£o MSE
    ‚îú‚îÄ‚îÄ mae_comparison.png          # Gr√°fico de compara√ß√£o MAE
    ‚îî‚îÄ‚îÄ mape_comparison.png         # Gr√°fico de compara√ß√£o MAPE
```

#### Descri√ß√£o dos Arquivos:

| Arquivo | Descri√ß√£o | Formato |
|---------|-----------|---------|
| `submission.csv` | Predi√ß√µes finais (`id`, `mean_1`, `std_1`, `mean_2`, `std_2`) | Pronto para submiss√£o |
| `metrics_report.csv` | M√©tricas comparativas (MSE, RMSE, MAE, MAPE, R¬≤) | An√°lise de performance |
| `best_hyperparameters.csv` | Melhores configura√ß√µes do RandomizedSearchCV | Para reprodutibilidade |
| `features_documentation.csv` | Justificativas t√©cnicas de cada feature criada | Documenta√ß√£o cient√≠fica |
| `figures/*.png` | Gr√°ficos de barras comparando modelos vs baseline | Visualiza√ß√£o executiva |
- Download autom√°tico dos dados via Google Drive
- Extra√ß√£o do arquivo ZIP na pasta `data/`
- Verifica√ß√£o de integridade dos arquivos
- Cria√ß√£o autom√°tica da estrutura de pastas se n√£o existir

### 2. üõ†Ô∏è Pr√©-processamento (`preprocessor.py`)

#### Agrega√ß√£o Temporal
- **Janelas de 5 minutos**: Reagrupamento dos dados originais
- **Sequ√™ncias de 1 hora**: 12 janelas consecutivas para extra√ß√£o de features

#### Feature Engineering
Para cada sequ√™ncia, s√£o extra√≠das as seguintes caracter√≠sticas:

| Feature | Descri√ß√£o | Justificativa |
|---------|-----------|---------------|
| `rate_mean` | M√©dia das taxas nos √∫ltimos 10 intervalos | Tend√™ncia central dos dados |
| `rate_std` | Desvio padr√£o nos √∫ltimos 10 intervalos | Variabilidade da rede |
| `last_rate` | √öltima taxa observada | Estado mais recente |
| `last_std` | √öltimo desvio padr√£o observado | Variabilidade recente |
| `coef_var` | Coeficiente de varia√ß√£o (std/mean) | Estabilidade relativa |
| `delta` | Diferen√ßa entre pen√∫ltimo e √∫ltimo valor | Tend√™ncia de mudan√ßa |
| `slope` | Inclina√ß√£o da regress√£o linear | Dire√ß√£o da tend√™ncia |

### 3. ü§ñ Modelagem (`model.py`)

#### Algoritmo Escolhido
**Random Forest** foi selecionado por:
- ‚úÖ Robustez a outliers
- ‚úÖ Capacidade de capturar rela√ß√µes n√£o-lineares
- ‚úÖ Interpretabilidade atrav√©s da import√¢ncia das features
- ‚úÖ Performance consistente em dados tabulares

#### Otimiza√ß√£o de Hiperpar√¢metros
```python
param_distributions = {
    'estimator__n_estimators': [50, 100, 200, 300],
    'estimator__max_depth': [10, 20, 30, None],
    'estimator__min_samples_split': [2, 5, 10],
    'estimator__min_samples_leaf': [1, 2, 4],
    'estimator__max_features': ['sqrt', 'log2', None]
}
```

### 4. üìä Avalia√ß√£o (`evaluator.py`)

#### M√©tricas de Performance
- **MSE** (Mean Squared Error): Penaliza erros grandes
- **RMSE** (Root Mean Squared Error): Interpret√°vel na unidade original
- **MAE** (Mean Absolute Error): Robusta a outliers
- **MAPE** (Mean Absolute Percentage Error): Erro relativo
- **R¬≤** (Coeficiente de Determina√ß√£o): Propor√ß√£o da vari√¢ncia explicada

#### Valida√ß√£o Temporal
- **TimeSeriesSplit**: Respeita a ordem cronol√≥gica dos dados
- **5 folds**: Avalia√ß√£o robusta da performance

### 5. üìà Resultados e Visualiza√ß√µes (`utils.py`)

#### Arquivos Gerados na Pasta `results/`
- `submission.csv`: Predi√ß√µes finais no formato solicitado
- `metrics_report.csv`: Compara√ß√£o detalhada das m√©tricas
- `best_hyperparameters.csv`: Melhores configura√ß√µes encontradas
- `features_documentation.csv`: Documenta√ß√£o das features criadas
- `performance_comparison.png`: Gr√°fico comparativo dos modelos

> **Nota**: A pasta `results/` √© criada automaticamente durante a execu√ß√£o

## üöÄ Como Executar

### 1. Pr√©-requisitos
```bash
# Python 3.12 ou superior
python --version

# Instalar depend√™ncias
pip install -r requirements.txt
```

### 2. Execu√ß√£o
```bash
# Executar pipeline completo
python main.py
```

O script ir√°:
1. Baixar os dados automaticamente para `data/`
2. Executar todo o pipeline de ML
3. Gerar todos os arquivos de resultado em `results/`
4. Exibir m√©tricas no console

> **üìÅ Pastas Criadas Automaticamente:**
> - `data/`: Cont√©m os dados originais baixados e extra√≠dos
> - `results/`: Cont√©m todos os artefatos gerados pelo pipeline

### 3. Estrutura dos Arquivos Ap√≥s Execu√ß√£o
```
ct-mon-challenge-SI/
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ open-data.zip               # Dataset original compactado
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ Train/dash/                 # Dados de treinamento por regi√£o
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ Test/                       # Dados de teste (*.json)
‚îî‚îÄ‚îÄ üìÅ results/
    ‚îú‚îÄ‚îÄ üìÑ submission.csv              # Predi√ß√µes finais
    ‚îú‚îÄ‚îÄ üìÑ metrics_report.csv          # Relat√≥rio de m√©tricas
    ‚îú‚îÄ‚îÄ üìÑ best_hyperparameters.csv    # Melhores hiperpar√¢metros
    ‚îú‚îÄ‚îÄ üìÑ features_documentation.csv  # Documenta√ß√£o das features
    ‚îî‚îÄ‚îÄ üìÅ figures/                    # Visualiza√ß√µes (PNG)
        ‚îú‚îÄ‚îÄ üìä mse_comparison.png
        ‚îú‚îÄ‚îÄ üìä mae_comparison.png
        ‚îî‚îÄ‚îÄ üìä mape_comparison.png
```

## üìä Resultados Obtidos

### Performance do Modelo

| Dataset | Modelo | MSE | RMSE | MAE | MAPE | R¬≤ |
|---------|--------|-----|------|-----|------|-----|
| **Treinamento** | Random Forest | 460M | 21.4K | 11.4K | 0.167 | **0.671** |
| Treinamento | Baseline | 1.38Bi | 37.2K | 22.4K | 0.250 | 0.000 |
| **Teste** | Random Forest | 477M | 21.8K | 11.5K | 0.064 | **0.654** |
| Teste | Baseline | 1.64Bi | 40.5K | 27.3K | 0.133 | -0.020 |

### üéØ Principais Conquistas

‚úÖ **67% de vari√¢ncia explicada** no conjunto de treinamento  
‚úÖ **65% de vari√¢ncia explicada** no conjunto de teste  
‚úÖ **Redu√ß√£o de 66% no MSE** comparado ao baseline  
‚úÖ **Redu√ß√£o de 48% no MAE** comparado ao baseline  
‚úÖ **Generaliza√ß√£o consistente** entre treino e teste  

## üõ†Ô∏è Tecnologias Utilizadas

### Core
- **Python 3.12+**: Linguagem principal
- **Scikit-learn**: Framework de machine learning
- **Pandas**: Manipula√ß√£o de dados
- **NumPy**: Computa√ß√£o num√©rica

### Espec√≠ficas
- **RandomForestRegressor**: Algoritmo de predi√ß√£o
- **MultiOutputRegressor**: M√∫ltiplas sa√≠das simult√¢neas
- **TimeSeriesSplit**: Valida√ß√£o temporal
- **RandomizedSearchCV**: Otimiza√ß√£o de hiperpar√¢metros

### Utilit√°rios
- **Matplotlib/Seaborn**: Visualiza√ß√µes
- **gdown**: Download autom√°tico de datasets
- **CSV/JSON**: Persist√™ncia de dados

## üîÆ Potenciais Extens√µes

### Curto Prazo
- [ ] **XGBoost/LightGBM**: Algoritmos de boosting
- [ ] **Feature Selection**: Sele√ß√£o autom√°tica de caracter√≠sticas
- [ ] **Cross-validation estratificada**: Por cliente/servidor

### M√©dio Prazo
- [ ] **LSTM/GRU**: Redes neurais recorrentes
- [ ] **Prophet**: Modelagem de sazonalidade
- [ ] **Ensemble Methods**: Combina√ß√£o de modelos

### Longo Prazo
- [ ] **Graph Neural Networks**: Explorar topologia da rede
- [ ] **Real-time Prediction**: Pipeline em tempo real
- [ ] **MLOps**: Deploy com MLflow/Kubeflow

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
